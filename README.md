# Preface

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## The Goal

Dự án này đóng vai trò như một bài kiểm tra cuối khóa cho một môn học
của tôi. Gần đây, [những
video](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
hướng dẫn tuyệt vời từ anh Karpathy đã mở ra cho tôi cái nhìn rõ ràng
hơn về Deep Learning và Large Language Model. Tuy nhiên, vì đang tự học,
tôi không chắc chắn liệu mình thực sự hiểu sâu hay chỉ tự cho rằng mình
đã hiểu. Điều này thúc đẩy tôi thực hiện dự án này với hy vọng nó không
chỉ giúp người khác hiểu rõ hơn về LLAMA2, mà còn giúp tôi chứng minh
rằng tôi đã thấu hiểu và có thể tiếp tục khám phá sâu hơn vào những kiến
thức chuyên sâu hơn.

## Why Llama2

Tôi quyết định lựa chọn Llama2 làm đề tài dự án của mình vì hiện tại nó
đang phổ biến và được rất nhiều người quan tâm. Điều này cũng được thúc
đẩy bởi vì anh Karpathy hiện đang trong quá trình thực hiện [video bài
giảng mới](https://github.com/karpathy/llama2.c) về LLAMA2. Do đó, việc
chọn đề tài này có thể được coi như một cơ hội để tôi chuẩn bị trước,
như việc tự chuẩn bị kiến thức trước khi đến lớp học của một giáo viên
đầy nhiệt huyết.

## Writing Style

Trong dự án này, mặc dù phần lớn sẽ được viết bằng tiếng Việt, tôi vẫn
lựa chọn sử dụng tiếng Anh cho các thuật ngữ. Lý do là khi viết code,
chúng ta thường sử dụng tiếng Anh cho tên biến và hàm, điều này giúp
tăng tính nhất quán và dễ đọc của mã code. Ví dụ, từ “Weight” thường
được viết tắt là “w” hoặc “weight” trong code, việc dịch sang “trọng số”
có thể làm tăng độ phức tạp không cần thiết.
